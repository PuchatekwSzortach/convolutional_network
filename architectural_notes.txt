

Model.fit:

    Shuffle data
    For each batch:

       - For each layer from start to end:

            Call train_forward() - does computations as in forward, but caches inputs and outputs

        - For each layer from end to start:

            Call train_backward() - performs backpropagation and applies results


Ok, what kind of tests could I write? What would I want to test?

Input layer - that shape is legal, that when compiling it sets output shape correctly and that during forward and train_forward
it checks for correct input and sets output

Flatten layer - that sets output_shape correctly at construction, that at compile accepts only shapes that can be squeezed to 2D,
    that during forward and train_forward outputs correct stuff

Softmax - that checks for legal input shape, that computes correct output, that computes correct loss,
    that compute correct loss derivative, that updates itself correctly, that passes correct loss to previous layer

Convolution2D - that creates correct kernels,
    that computes correct convolutions, that computes correct derivatives, that updates itself correctly


Ok, what do we want to test with Model:
- test model calls proper functions for fit

Ok, now how will model.fit(x) work?

    Shuffle data

    For batch in data:

        x = batch

        for layer in self.layers:

            x = layer.train_forward(x)

        gradients = 1

        for layer in reversed(self.layers):

            gradients = layer.train_backward(gradients, learning_rate)

I guess :P

Ok, so what components are needed for backpropagation?

Our fit will have fit_batch().
fit_batch() would do:
- model would calculate loss
- pass that loss to softmax
- softmax would calculate gradiens to its preactivation
- flatten would calculate its gradients
- input would have a no op there I guess
- convolution 2D would do its gradients

start with model.get_loss()